{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08948ec0-620d-46fc-b38d-5ca0fafa75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/root/workspace/read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d8fde1-5e4e-4093-9752-52c39a99bf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/read/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa2a720-7f25-42c4-9b5f-4f3d772e601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to initialize pre-built index wikipedia-dpr.\n",
      "Downloading index at https://rgw.cs.uwaterloo.ca/JIMMYLIN-bucket0/pyserini-indexes/index-wikipedia-dpr-20210120-d1b9e6.tar.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "index-wikipedia-dpr-20210120-d1b9e6.tar.gz:  53%|█████████        | 4.57G/8.55G [11:01<09:37, 7.41MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyserini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaissSearcher, DprQueryEncoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyserini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhybrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HybridSearcher\n\u001b[0;32m----> 5\u001b[0m ssearcher \u001b[38;5;241m=\u001b[39m \u001b[43mLuceneSearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_prebuilt_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwikipedia-dpr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m encoder \u001b[38;5;241m=\u001b[39m DprQueryEncoder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/dpr-question_encoder-multiset-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m dsearcher \u001b[38;5;241m=\u001b[39m FaissSearcher\u001b[38;5;241m.\u001b[39mfrom_prebuilt_index(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikipedia-dpr-multi-bf\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoder\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/site-packages/pyserini/search/lucene/_searcher.py:70\u001b[0m, in \u001b[0;36mLuceneSearcher.from_prebuilt_index\u001b[0;34m(cls, prebuilt_index_name)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to initialize pre-built index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprebuilt_index_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     index_dir \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_prebuilt_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprebuilt_index_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/site-packages/pyserini/util.py:231\u001b[0m, in \u001b[0;36mdownload_prebuilt_index\u001b[0;34m(index_name, force, verbose, mirror)\u001b[0m\n\u001b[1;32m    229\u001b[0m local_filename \u001b[38;5;241m=\u001b[39m target_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m target_index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload_and_unpack_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprebuilt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_md5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPError, URLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to download pre-built index at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, trying next URL...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/site-packages/pyserini/util.py:149\u001b[0m, in \u001b[0;36mdownload_and_unpack_index\u001b[0;34m(url, index_directory, local_filename, force, verbose, prebuilt, md5)\u001b[0m\n\u001b[1;32m    146\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(index_path)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading index at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 149\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_tarball\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/site-packages/pyserini/util.py:94\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, save_dir, local_filename, md5, force, verbose)\u001b[0m\n\u001b[1;32m     91\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(destination_path)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TqdmUpTo(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, miniters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, desc\u001b[38;5;241m=\u001b[39mfilename) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m md5:\n\u001b[1;32m     97\u001b[0m     md5_computed \u001b[38;5;241m=\u001b[39m compute_md5(destination_path)\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/urllib/request.py:276\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    273\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/envs/read/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.search.faiss import FaissSearcher, DprQueryEncoder\n",
    "from pyserini.search.hybrid import HybridSearcher\n",
    "\n",
    "ssearcher = LuceneSearcher.from_prebuilt_index(\"wikipedia-dpr\")\n",
    "\n",
    "encoder = DprQueryEncoder(\"facebook/dpr-question_encoder-multiset-base\")\n",
    "dsearcher = FaissSearcher.from_prebuilt_index(\n",
    "    \"wikipedia-dpr-multi-bf\", encoder\n",
    ")\n",
    "searcher = HybridSearcher(dsearcher, ssearcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50866d68-bae1-4570-8290-2dcf4aea4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../data/totto/augmented/train.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74c566f-8821-4e0e-98a0-6337aec4b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_content(raw_content: str) -> str:\n",
    "    title, content = json.loads(raw_content)[\"contents\"].split(\"\\n\", 1)\n",
    "    return title[1:-1], content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb04d631-2b35-4a53-952b-423e05ec86fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read.utils.table import linearize\n",
    "from torchmetrics import RetrievalHitRate, RetrievalRPrecision, RetrievalRecall, RetrievalPrecision, RetrievalMRR, RetrievalMAP\n",
    "\n",
    "\n",
    "k2metrics = {k: [RetrievalHitRate(k=k), RetrievalRPrecision(k=k), RetrievalRecall(k=k), RetrievalPrecision(k=k), RetrievalMRR(k=k), RetrievalMAP(k=k)] for k in [1, 5, 10]}\n",
    "\n",
    "\n",
    "preds = []\n",
    "indices = []\n",
    "golds = []\n",
    "\n",
    "prediction_data = []\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "for idx, row in df.iloc[:100].iterrows():\n",
    "    one_prediction = []\n",
    "    table = row[\"table\"]\n",
    "    query = linearize(table, row[\"highlighted_cells\"], row_sep=\" ; \", value_sep=\" : \", includes_header=True, return_text=True)\n",
    "    \n",
    "    hits = searcher.search(query, k=10)\n",
    "    \n",
    "    for hit in hits:\n",
    "        doc = ssearcher.doc(hit.docid)\n",
    "        title, text = process_content(doc.raw())\n",
    "        \n",
    "        preds.append(hit.score)\n",
    "        indices.append(idx)\n",
    "        golds.append(title == row[\"table_page_title\"])\n",
    "        \n",
    "        # if title == row[\"table_page_title\"]:\n",
    "        #     print(f\"Title: '{title}' with query ({query}) for sentence ({row['sentence']})\\n\")\n",
    "        #     print(f\"Label: {row['negatives'] is not None}\\n and index {idx}\")\n",
    "        #     print(f\"Text: {text}\\n\")\n",
    "\n",
    "        one_prediction.append({\"idx\": idx, \"title\": title, \"text\": text, \"score\": hit.score, \"gold\": row[\"table_page_title\"], \"table\": table, \"query\": query, \"sentence\": row[\"sentence_annotations\"]})\n",
    "    prediction_data.append(one_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da3ada-b239-46f1-9c14-16994f31b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "result = {}\n",
    "\n",
    "preds = torch.tensor(preds)\n",
    "golds = torch.tensor(golds)\n",
    "indices = torch.tensor(indices)\n",
    "\n",
    "for k, metrics in k2metrics.items():\n",
    "    for metric in metrics:\n",
    "        result[f\"{metric.__class__.__name__}@{k}\"] = metric(preds, golds, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f98d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6d534-6e32-430a-a5e6-ffbbfb0ee841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d08430-a23e-48ce-a9da-9a6ceecb0747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of torch.overrides failed: Traceback (most recent call last):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/overrides.py\", line 1512, in <module>\n",
      "    has_torch_function = _add_docstr(\n",
      "RuntimeError: function '_has_torch_function' already has a docstring\n",
      "]\n",
      "[autoreload of torch._tensor failed: Traceback (most recent call last):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/_tensor.py\", line 84, in <module>\n",
      "    class Tensor(torch._C._TensorBase):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/_tensor.py\", line 467, in Tensor\n",
      "    detach = _C._add_docstr(_C._TensorBase.detach, r\"\"\"\n",
      "RuntimeError: method 'detach' already has a docstring\n",
      "]\n",
      "[autoreload of torch.cuda.amp.autocast_mode failed: Traceback (most recent call last):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py\", line 13, in <module>\n",
      "    class autocast(torch.amp.autocast_mode.autocast):\n",
      "AttributeError: module 'torch.amp' has no attribute 'autocast_mode'\n",
      "]\n",
      "[autoreload of torch.sparse failed: Traceback (most recent call last):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/sparse/__init__.py\", line 28, in <module>\n",
      "    addmm = _add_docstr(_sparse._sparse_addmm, r\"\"\"\n",
      "RuntimeError: function '_sparse_addmm' already has a docstring\n",
      "]\n",
      "[autoreload of torch._torch_docs failed: Traceback (most recent call last):\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/_torch_docs.py\", line 131, in <module>\n",
      "    add_docstr(torch.abs, r\"\"\"\n",
      "RuntimeError: function 'abs' already has a docstring\n",
      "]\n",
      "/nas/home/minhpham/miniconda3/envs/read/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fe1fe-7662-453b-8f3f-2e9db3f7496e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b04cdd20d906f01249004a00e02b15317fd602467e42d5d2658435d7da6fec22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
